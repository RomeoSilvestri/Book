{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d75934",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "With the problem identified and project objectives determined, the next critical phase in the data science lifecycle is the specification of project evaluation metrics. These metrics serve as the yardsticks by which the success of the project is measured and provide a quantitative assessment of how well the objectives are met. Let's delve into the key components of specifying project evaluation metrics:\n",
    "\n",
    "**Alignment with Objectives**\n",
    "\n",
    "The chosen evaluation metrics must align closely with the project objectives. In the case of predicting residential property prices in Madrid, where the primary objective is to minimize prediction error, the selected metrics should effectively quantify the accuracy and precision of the predictive models.\n",
    "\n",
    "**Quantifiable Measures** and **Business Relevance**\n",
    "\n",
    "Evaluation metrics should be quantifiable and provide a clear measure of the model's performance. Evaluation metrics should not only be technically sound but also relevant to the business context. In the real estate market example, the selected metrics directly relate to the accuracy of property price predictions, a critical factor for both buyers and sellers in making informed decisions. For our example, two commonly used metrics are the MSE and the MAE.\n",
    "\n",
    "**Comprehensive and Dynamic View of Performance**\n",
    "\n",
    "The combination of MSE and MAE provides a comprehensive view of the model's performance. MSE penalizes larger errors more heavily, while MAE provides a more straightforward measure of average prediction accuracy. Together, they offer insights into different aspects of the model's predictive capabilities. The choice of evaluation metrics may evolve as the project progresses. It's essential to remain flexible and adapt metrics based on the evolving needs of the project or new insights gained during the analysis.\n",
    "\n",
    "**Communication of Metrics**\n",
    "\n",
    "Clear communication of the selected evaluation metrics to all stakeholders is vital. This ensures that everyone involved has a shared understanding of how success will be measured and what specific aspects of model performance are most critical.\n",
    "\n",
    "**Continuous Monitoring**\n",
    "\n",
    "Project evaluation is not a one-time activity. Continuous monitoring of the selected metrics throughout the project allows for early detection of issues and timely adjustments to improve model performance.\n",
    "\n",
    "In conclusion, the specification of project evaluation metrics is a strategic step that ensures the project remains on track towards achieving its objectives. By aligning metrics with project goals, making them quantifiable and relevant, and establishing clear thresholds for success, the project team can systematically assess and improve the performance of predictive models."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "source_map": [
   13
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}